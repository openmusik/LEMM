# LEMM Configuration File
# Version: 0.1.0

server:
  host: "0.0.0.0"
  port: 7860
  share: false
  debug: false

audio:
  sample_rate: 44100
  clip_duration: 32  # seconds
  lead_in_duration: 2  # seconds
  lead_out_duration: 2  # seconds
  main_duration: 28  # seconds
  crossfade_duration: 2  # seconds

models:
  ace_step:
    # ACE-Step model configuration
    path: "models/ACE-Step-HF"  # Local model path
    device: "auto"  # "auto" for detection, "cuda", or "cpu"
    device_id: 0  # GPU device ID
    bf16: true  # Use bfloat16 for faster inference (requires CUDA)
    torch_compile: false  # Use torch.compile() for optimization (slower startup)
    cpu_offload: false  # Offload weights to CPU to save VRAM
    overlapped_decode: false  # Use overlapped decoding for speed
    num_inference_steps: 27  # 27 for fast, 60 for quality
    guidance_scale: 7.5
    max_duration: 60  # seconds per generation
    use_local: true  # Use local downloaded model
  
  song_composer:
    path: "models/song_composer"  # Not yet available
    device: "cuda"
    enabled: false
  
  music_control_net:
    path: "models/music_control_net"  # Not yet available
    device: "cuda"
    enabled: false
  
  demucs:
    model: "htdemucs"  # or "htdemucs_ft" for fine-tuned
    device: "cuda"
    shifts: 1  # Number of random shifts for better separation
    split: true  # Split audio for lower memory usage
    overlap: 0.25
  
  so_vits_svc:
    path: "models/sovits"
    device: "cuda"
    config_path: "models/sovits/config.json"  # Will be created
    hubert_path: "models/sovits/hubert_base.pt"
    content_vec_path: "models/sovits/content_vec.pth"
  
  vocal_synthesis:
    # Text-to-Singing synthesis for MusicGen vocals
    backend: "auto"  # "auto", "piper", "bark", "placeholder"
    device: "auto"  # "auto", "cuda", "cpu"
    sample_rate: 44100
    preload_models: false  # For Bark - preload for faster synthesis
    max_chars: 2000  # Maximum characters to synthesize
    voice_preset: "v2/en_speaker_6"  # Bark voice preset (if using Bark)

generation:
  default_clips: 3
  max_clips: 10
  temperature: 1.0
  top_p: 0.95
  guidance_scale: 7.5

lora:
  enabled: false
  path: null
  alpha: 1.0
  rank: 16

output:
  directory: "output"
  format: "wav"  # wav or mp3
  export_stems: false
  bitrate: 320  # for MP3

training:
  batch_size: 4
  learning_rate: 0.0001
  num_epochs: 10
  gradient_accumulation_steps: 4
  save_steps: 100
  logging_steps: 10

datasets:
  # Automatic dataset downloading for HuggingFace Spaces
  auto_download: true  # Automatically download datasets on Space startup
  phase: "minimal"  # "minimal" (54GB), "balanced" (120GB), or "comprehensive" (227GB)
  cache_dir: "datasets"  # Local cache directory
  use_hf_cache: true  # Use HuggingFace's cache system (recommended for Spaces)
  max_storage_gb: 150  # Maximum storage to use for datasets
  
  # Dataset priorities (1-5, higher = download first)
  priorities:
    nsynth: 5  # Essential for music synthesis
    ljspeech: 5  # Essential for vocal synthesis
    urmp: 4  # Multi-instrument coordination
    fma_small: 4  # Genre diversity
    libritts: 3  # Multi-speaker vocals
    musicnet: 3  # Classical notation
    fma_large: 2  # Extended genre coverage
    lakh_midi: 3  # Symbolic music

